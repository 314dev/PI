name: Test slow

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on:  # Trigger the workflow on push or pull request, but only for the master branch
  push:
    branches: [master, "release/*"]
  pull_request:
    branches: [master, "release/*"]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref }}
  cancel-in-progress: ${{ ! (github.ref == 'refs/heads/master' || startsWith(github.ref, 'refs/heads/release/')) }}

jobs:
  slow:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macOS-latest]
        # same config as '.azure-pipelines/gpu-tests.yml'
        python-version: ["3.7"]
        pytorch-version: ["1.8"]

    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v2
    - uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}

    - name: Weekly reset caching
      run: echo "::set-output name=period::$(python -c 'import time ; days = time.time() / 60 / 60 / 24 ; print(int(days / 7))' 2>&1)"
      id: times

    - name: Get pip cache
      id: pip-cache
      run: |
        python -c "from pip._internal.locations import USER_CACHE_DIR; print('::set-output name=dir::' + USER_CACHE_DIR)"

    - name: Cache pip
      uses: actions/cache@v2
      with:
        path: ${{ steps.pip-cache.outputs.dir }}
        key: ${{ runner.os }}-pip-td${{ steps.times.outputs.period }}-py${{ matrix.python-version }}-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-td${{ steps.times.outputs.period }}-py${{ matrix.python-version }}-

    - name: Install dependencies
      run: |
        # adjust versions according installed Torch version
        python ./requirements/adjust_versions.py requirements.txt ${{ matrix.pytorch-version }}
        pip install --requirement requirements.txt --find-links https://download.pytorch.org/whl/cpu/torch_stable.html --upgrade
        pip install --requirement requirements/test.txt
        pip list
      shell: bash

    - name: Tests
      run: |
        coverage run --source pi_ml -m pytest tests -v --junitxml=junit/test-results-${{ runner.os }}-${{ matrix.python-version }}.xml
      env:
        PL_RUN_SLOW_TESTS: 1

    - name: Upload pytest test results
      uses: actions/upload-artifact@v2
      with:
        name: pytest-results-${{ runner.os }}-${{ matrix.python-version }}
        path: junit/test-results-${{ runner.os }}-${{ matrix.python-version }}.xml
      if: failure()

    - name: Statistics
      if: success()
      run: |
        coverage report
        coverage xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v1
      if: success()
      # see: https://github.com/actions/toolkit/issues/399
      continue-on-error: true
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: coverage.xml
        flags: cpu,pytest,torch${{ matrix.pytorch-version }}
        name: CPU-coverage
        fail_ci_if_error: false
